import os
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip

# âœ… ë¬¸ì¥ ë°˜ ë‚˜ëˆ„ëŠ” ìë§‰ ìƒì„± í•¨ìˆ˜
def create_video_with_split_subtitles(video_filenames, subtitles, durations, font_path, font_size, text_color, subtitle_y_position):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ë“¤ê³¼ ìë§‰(ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)ê³¼ ê° ìë§‰ durationì„ ë°›ì•„
    ë¬¸ì¥ ë°˜ ë‚˜ëˆ ì„œ ìë§‰ì„ ì…íŒ ë¹„ë””ì˜¤ í´ë¦½ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    """
    video_clips = []

    for idx, video_filename in enumerate(video_filenames):
        video_path = os.path.join("videos", video_filename)

        if not os.path.exists(video_path):
            raise FileNotFoundError(f"{video_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        clip = VideoFileClip(video_path)
        subtitle_text = subtitles[idx]
        words = subtitle_text.strip().split()
        half = (len(words) + 1) // 2

        first_sub = " ".join(words[:half])
        second_sub = " ".join(words[half:])

        duration = durations[idx]

        first_subtitle = (
            TextClip(
                first_sub,
                fontsize=font_size,
                color=text_color,
                font=font_path,
                size=(clip.w, 100 + 50),
                method='caption'
            )
            .set_position(("center", clip.h + subtitle_y_position))
            .set_start(0)
            .set_duration(duration)
        )

        second_subtitle = (
            TextClip(
                second_sub,
                fontsize=font_size,
                color=text_color,
                font=font_path,
                size=(clip.w, 100 + 50),
                method='caption'
            )
            .set_position(("center", clip.h + subtitle_y_position))
            .set_start(duration)
            .set_duration(clip.duration - duration)
        )

        video_with_subtitles = CompositeVideoClip([clip, first_subtitle, second_subtitle])
        video_clips.append(video_with_subtitles)

    return video_clips


# âœ… ë‹¨ì–´ë³„ë¡œ íŠ€ì–´ë‚˜ì˜¤ëŠ” ìë§‰ ìƒì„± í•¨ìˆ˜
def create_video_with_word_subtitles(video_filenames, subtitles, word_timings_list, font_path, font_size, text_color, subtitle_y_position):
    """
    ìì—°ìŠ¤ëŸ½ê²Œ ë³‘í•©ëœ ë‹¨ì–´ ìë§‰ì„ ì˜ìƒì— ì…íˆëŠ” í•¨ìˆ˜
    """
    video_clips = []
    interval = 5  # ê° í´ë¦½ì˜ ì˜ˆìƒ ì¬ìƒ ì‹œê°„ ê°„ê²© (ì´ˆ ë‹¨ìœ„) â€” TTS ê¸°ì¤€

    for idx, video_filename in enumerate(video_filenames):
        video_path = os.path.join("videos", video_filename)
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"{video_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        clip = VideoFileClip(video_path)
        subtitle_text = subtitles[idx].strip()
        subtitle_words = subtitle_text.split()
        whisper_word_timings = word_timings_list[idx]

        # 1. Whisper-ìë§‰ ì •ë ¬
        aligned_word_timings = align_words_with_timings_split(subtitle_words, whisper_word_timings)

        # 2. ìì—°ìŠ¤ëŸ½ê²Œ ë³‘í•©
        merged_word_timings = merge_natural_korean_phrases(aligned_word_timings)

        print(f"\nğŸ§¾ [ì¸ë±ìŠ¤ {idx}] ë³‘í•© ì „ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸:")
        for w in aligned_word_timings:
            print(f" - {w['word']} | {w['start']} ~ {w['end']}")

        print(f"\nğŸ§¾ [ì¸ë±ìŠ¤ {idx}] ë³‘í•© í›„ ìë§‰ ë¦¬ìŠ¤íŠ¸:")
        for w in merged_word_timings:
            print(f"ğŸ“ {w['word']} | {w['start']} ~ {w['end']}")


        # 3. ìë§‰ í´ë¦½ ìƒì„±
        clip_start_time = idx * interval
        word_clips = []

        for word_info in merged_word_timings:
            global_start = word_info["start"]
            global_end = word_info["end"]
            local_start = round(global_start - clip_start_time, 2)
            local_end = round(global_end - clip_start_time, 2)
            duration = round(local_end - local_start, 2)

            # ì˜ìƒ ë²”ìœ„ ë²—ì–´ë‚œ ìë§‰ ì œê±°
            if local_start < 0 or local_start >= clip.duration:
                continue
            if local_end > clip.duration:
                local_end = clip.duration
                duration = round(local_end - local_start, 2)

            txt = TextClip(
                word_info["word"],
                fontsize=font_size,
                color=text_color,
                font=font_path,
                size=(clip.w, 200),
                method='caption'
            ).set_position(("center", clip.h + subtitle_y_position))

            pop = txt.resize(lambda t: 0.3 + 0.7 * (t / 0.2) if t < 0.2 else 1)
            pop = pop.set_start(local_start).set_duration(duration)
            pop = pop.set_start(local_start).set_duration(duration)
            word_clips.append(pop)

        # ì˜ìƒ + ìë§‰ í•©ì„±
        final = CompositeVideoClip([clip] + word_clips).set_duration(clip.duration)
        video_clips.append(final)

    return video_clips

def merge_short_words(word_timings):
    """
    Whisper ë¶„ì„ ê²°ê³¼ì—ì„œ ë‹¨ì–´ê°€ ì§§ì„ ê²½ìš°(6ì ì´í•˜), ë‹¤ìŒ ë‹¨ì–´ì™€ ìë§‰ì„ ë³‘í•©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì¶œë ¥ë˜ë„ë¡ ì •ë¦¬.

    Args:
        word_timings (List[dict]): ë‹¨ì–´ ë‹¨ìœ„ Whisper ê²°ê³¼
            ì˜ˆ: [{"word": "í• ", "start": 0.0, "end": 0.3}, ...]

    Returns:
        List[dict]: ë³‘í•©ëœ ìë§‰ ë¦¬ìŠ¤íŠ¸
            ì˜ˆ: [{"word": "í•  ìˆ˜", "start": 0.0, "end": 0.6}, ...]
    """
    merged = []
    i = 0

    while i < len(word_timings):
        current = word_timings[i]
        current_word = current["word"].strip()
        current_len = len(current_word)

        # ë§ˆì§€ë§‰ ë‹¨ì–´ê±°ë‚˜ ë‹¤ìŒ ë‹¨ì–´ê°€ ì—†ìŒ
        if i == len(word_timings) - 1:
            merged.append(current)
            break

        next_word = word_timings[i + 1]["word"].strip()
        next_len = len(next_word)

        # ë‘ ë‹¨ì–´ ëª¨ë‘ 6ê¸€ì ì´í•˜ â†’ ë³‘í•©
        if current_len <= 6 and next_len <= 6:
            merged_word = f"{current_word} {next_word}"
            merged_clip = {
                "word": merged_word,
                "start": current["start"],
                "end": word_timings[i + 1]["end"]
            }
            merged.append(merged_clip)
            i += 2  # ë‘ ë‹¨ì–´ ê±´ë„ˆë›°ê¸°
        else:
            # ë³‘í•©í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ
            merged.append(current)
            i += 1

    return merged


def merge_natural_korean_phrases(word_timings):
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ìë§‰ ë³‘í•© (ì¡°ì‚¬ ë ë‹¨ì–´ ë³‘í•© ê¸ˆì§€, ì¡°ì‚¬ ë‹¨ì–´ëŠ” ì• ë‹¨ì–´ì— ë³‘í•©)
    """
    merged = []
    i = 0
    josa_list = ["ì„", "ë¥¼", "ì´", "ê°€", "ì€", "ëŠ”", "ì—", "ì—ì„œ", "ìœ¼ë¡œ", "ì™€", "ê³¼", "ë„", "ë§Œ", "ë¶€í„°", "ê¹Œì§€", "ì²˜ëŸ¼", "ë³´ë‹¤"]

    while i < len(word_timings):
        current = word_timings[i]
        curr_word = current["word"].strip()

        if i == len(word_timings) - 1:
            merged.append(current)
            break

        next_word_obj = word_timings[i + 1]
        next_word = next_word_obj["word"].strip()

        def should_merge(prev, curr):
            # ì‰¼í‘œ ìˆëŠ” ë‹¨ì–´ëŠ” ë³‘í•© ê¸ˆì§€
            if "," in prev or "," in curr:
                return False
            # ì• ë‹¨ì–´ê°€ ì¡°ì‚¬ë¡œ ëë‚˜ëŠ” ê²½ìš° ë³‘í•© ê¸ˆì§€
            if any(prev.endswith(josa) for josa in josa_list):
                return False
            # ë’· ë‹¨ì–´ê°€ ì¡°ì‚¬ í•˜ë‚˜ë©´ ë³‘í•© (ì˜ˆ: "ì„")
            if curr in josa_list:
                return True
            # ë‘˜ ë‹¤ ì§§ì€ ë‹¨ì–´ë©´ ë³‘í•© í—ˆìš©
            if len(prev) <= 6 and len(curr) <= 6:
                return True
            return False

        if should_merge(curr_word, next_word):
            merged.append({
                "word": f"{curr_word} {next_word}",
                "start": current["start"],
                "end": next_word_obj["end"]
            })
            i += 2
        else:
            merged.append(current)
            i += 1

    return merged




# ì‚¬ìš©ì ì…ë ¥ ìë§‰ê³¼ whisperëª¨ë“ˆì´ ë¶„ì„í•œ ìë§‰ì´ ì„œë¡œ ë§ì§€ ì•Šì•„ ì¸ë±ìŠ¤ ì°¨ì´ì™€ ë§ì¶¤ë²• ì°¨ì´ê°€ ë°œìƒ
#ì•„ë˜ í•¨ìˆ˜ ì¶”ê°€í•˜ì—¬ ttsê°€ ë‹¨ì–´ë¥¼ ì½ì€ ì‹œê°„ì„ ê°€ì ¸ì˜¤ê³  ìë§‰ì€ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²ƒìœ¼ë¡œ ì¹˜í™˜
#ì•„ì§ ì‹±í¬ê°€ ì •í™•íˆ ë§ì§€ë„ ì•Šê³  ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ê²Œ ë½‘í˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ 54ì´ˆ ì˜¤ì°¨ë²”ìœ„ 2ì´ˆ -> ì˜¤ë˜ê±¸ë¦¬ëŠ” ì´ìœ ëŠ” whisper ëª¨ë¸ì´ ì»¤ì„œ. ì‘ì€ ëª¨ë¸ ì‚¬ìš©í•˜ë©´ 10ì´ˆ ë‚´ì™¸
def align_words_with_timings_split(subtitle_words, whisper_words):
    """
    Whisper ë‹¨ì–´ êµ¬ê°„ì— ì—¬ëŸ¬ ìë§‰ ë‹¨ì–´ê°€ ë§¤í•‘ë  ê²½ìš° ì‹œê°„ ë¶„ë°° ë°©ì‹ìœ¼ë¡œ ì •ë ¬
    """
    aligned_words = []
    whisper_idx = 0
    subtitle_idx = 0

    while subtitle_idx < len(subtitle_words) and whisper_idx < len(whisper_words):
        w_sub = subtitle_words[subtitle_idx]
        w_whisper = whisper_words[whisper_idx]["word"]
        start = whisper_words[whisper_idx]["start"]
        end = whisper_words[whisper_idx]["end"]

        # ìë§‰ ë‹¨ì–´ë“¤ì„ Whisper ë‹¨ì–´ì— ìµœëŒ€í•œ ë§¤í•‘
        matched = []
        temp_idx = subtitle_idx
        merged = ""

        while temp_idx < len(subtitle_words) and len(merged.replace(" ", "")) < len(w_whisper.replace(" ", "")):
            merged += subtitle_words[temp_idx]
            matched.append(subtitle_words[temp_idx])
            temp_idx += 1

        if len(matched) > 0:
            part_duration = (end - start) / len(matched)
            for i, word in enumerate(matched):
                word_start = round(start + i * part_duration, 2)
                word_end = round(word_start + part_duration, 2)
                aligned_words.append({
                    "word": word,
                    "start": word_start,
                    "end": word_end
                })
            subtitle_idx += len(matched)
        whisper_idx += 1

    return aligned_words


def create_video_with_custom_chunks(video_filenames, subtitle_chunks_list, whisper_word_timings_list, font_path, font_size, text_color, subtitle_y_position):
    """
    ì‚¬ìš©ìê°€ ì§ì ‘ ì •ì˜í•œ ìë§‰ ë©ì–´ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ poping ì• ë‹ˆë©”ì´ì…˜ ìë§‰ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    Whisper ë‹¨ì–´ íƒ€ì´ë°ê³¼ ë§¤ì¹­í•˜ì—¬ ê° ë©ì–´ë¦¬ì˜ ì‹œì‘/ë ì‹œê°„ìœ¼ë¡œ ìë§‰ ì²˜ë¦¬.

    Args:
        video_filenames (List[str]): ë¹„ë””ì˜¤ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸
        subtitle_chunks_list (List[List[str]]): ê° ë¬¸ì¥ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ë‚˜ëˆˆ ìë§‰ ë©ì–´ë¦¬ ë¦¬ìŠ¤íŠ¸
        whisper_word_timings_list (List[List[dict]]): Whisperë¡œ ë¶„ì„ëœ ë‹¨ì–´ë³„ íƒ€ì´ë° ë¦¬ìŠ¤íŠ¸
        font_path (str): í°íŠ¸ ì´ë¦„
        font_size (int): ê¸€ì í¬ê¸°
        text_color (str): ê¸€ì ìƒ‰
        subtitle_y_position (int): ìë§‰ Yì¶• ìœ„ì¹˜ ì˜¤í”„ì…‹

    Returns:
        List[VideoClip]: ìë§‰ì´ ì…í˜€ì§„ ë¹„ë””ì˜¤ í´ë¦½ ë¦¬ìŠ¤íŠ¸
    """
    from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip

    interval = 5  # ê° í´ë¦½ì˜ ì‹œì‘ ì‹œê°„ ì˜¤í”„ì…‹
    video_clips = []

    for idx, video_filename in enumerate(video_filenames):
        video_path = os.path.join("videos", video_filename)
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"{video_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        clip = VideoFileClip(video_path)
        subtitle_chunks = subtitle_chunks_list[idx]
        whisper_word_timings = whisper_word_timings_list[idx]

        # ì‚¬ìš©ì ìë§‰ ë©ì–´ë¦¬ë¥¼ Whisper íƒ€ì´ë°ê³¼ ë§¤ì¹­
        aligned_chunks = align_custom_subtitles_with_timings(subtitle_chunks, whisper_word_timings)

        print(f"\nğŸ§¾ [ì¸ë±ìŠ¤ {idx}] ì‚¬ìš©ì ì •ì˜ ìë§‰ íƒ€ì´ë°:")
        for w in aligned_chunks:
            print(f"ğŸ“ {w['word']} | {w['start']} ~ {w['end']}")

        # ìë§‰ í´ë¦½ ìƒì„±
        clip_start_time = idx * interval
        word_clips = []

        for chunk in aligned_chunks:
            global_start = chunk["start"]
            global_end = chunk["end"]
            local_start = round(global_start - clip_start_time, 2)
            local_end = round(global_end - clip_start_time, 2)
            duration = round(local_end - local_start, 2)

            # ë²”ìœ„ ë²—ì–´ë‚˜ëŠ” ìë§‰ ì œì™¸
            if local_start < 0 or local_start >= clip.duration:
                continue
            if local_end > clip.duration:
                local_end = clip.duration
                duration = round(local_end - local_start, 2)

            txt = TextClip(
                chunk["word"],
                fontsize=font_size,
                color=text_color,
                font=font_path,
                size=(clip.w, 150),
                method='caption'
            ).set_position(("center", clip.h + subtitle_y_position))

            pop = txt.resize(lambda t: 0.3 + 0.7 * (t / 0.2) if t < 0.2 else 1)
            pop = pop.set_start(local_start).set_duration(duration)
            word_clips.append(pop)

        # ì˜ìƒê³¼ ìë§‰ í•©ì„±
        final = CompositeVideoClip([clip] + word_clips).set_duration(clip.duration)
        video_clips.append(final)

    return video_clips

def align_custom_subtitles_with_timings(subtitle_chunks, whisper_word_timings):
    aligned_chunks = []
    whisper_idx = 0
    last_end_time = whisper_word_timings[-1]["end"] if whisper_word_timings else 0.0

    for chunk in subtitle_chunks:
        chunk_words = chunk.strip().split()
        chunk_len = len(chunk_words)
        matched_words = []

        while whisper_idx < len(whisper_word_timings) and len(matched_words) < chunk_len:
            matched_words.append(whisper_word_timings[whisper_idx])
            whisper_idx += 1

        # âœ… ë§¤ì¹­ëœ ê²ƒì´ ìˆìœ¼ë©´ ì •ìƒ ì²˜ë¦¬
        if matched_words:
            start_time = matched_words[0]["start"]
            end_time = matched_words[-1]["end"]
            aligned_chunks.append({
                "word": chunk,
                "start": round(start_time, 2),
                "end": round(end_time, 2)
            })
        else:
            # âœ… Whisper íƒ€ì´ë°ì´ ëë‚¬ì§€ë§Œ ìë§‰ì´ ë‚¨ì€ ê²½ìš° â†’ ë§ˆì§€ë§‰ ì‹œê°„ ì´í›„ë¡œ ì²˜ë¦¬
            aligned_chunks.append({
                "word": chunk,
                "start": round(last_end_time, 2),
                "end": round(last_end_time + 0.5, 2)  # ëŒ€ëµì ì¸ ê¸¸ì´ í• ë‹¹
            })
            last_end_time += 0.5  # ë‹¤ìŒ ìë§‰ì„ ìœ„í•´ ì˜¤í”„ì…‹ ì´ë™

    return aligned_chunks


#ì‚¬ì‹¤ìƒ ê¸°ì¡´ê³¼ ë™ì¼
def create_video_with_poping_subtitles(video_filenames, subtitles, word_timings_list, font_path, font_size, text_color, subtitle_y_position):
    """
    ê¸€ìê°€ ì‘ê²Œ ì‹œì‘í•´ì„œ ì»¤ì§€ëŠ” íŒì—… ì• ë‹ˆë©”ì´ì…˜ì„ ì ìš©í•˜ë˜ ì„ ëª…ë„ë¥¼ ìœ ì§€í•œ ë²„ì „
    """
    from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip

    video_clips = []
    interval = 5

    for idx, video_filename in enumerate(video_filenames):
        video_path = os.path.join("videos", video_filename)
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"{video_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        clip = VideoFileClip(video_path)
        subtitle_text = subtitles[idx].strip()
        subtitle_words = subtitle_text.split()
        whisper_word_timings = word_timings_list[idx]

        aligned_word_timings = align_words_with_timings_split(subtitle_words, whisper_word_timings)
        merged_word_timings = merge_natural_korean_phrases(aligned_word_timings)

        word_clips = []
        clip_start_time = idx * interval

        for word_info in merged_word_timings:
            global_start = word_info["start"]
            global_end = word_info["end"]
            local_start = round(global_start - clip_start_time, 2)
            local_end = round(global_end - clip_start_time, 2)
            duration = round(local_end - local_start, 2)

            if local_start < 0 or local_start >= clip.duration:
                continue
            if local_end > clip.duration:
                local_end = clip.duration
                duration = round(local_end - local_start, 2)

            # ê³ í•´ìƒë„ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ í›„ ì ˆë°˜ í¬ê¸°ë¡œ ê¸°ë³¸ ì‚¬ì´ì¦ˆ ì„¤ì •
            txt = TextClip(
                word_info["word"],
                fontsize=font_size * 2,
                color=text_color,
                font=font_path,
                size=(clip.w * 2, 300),
                method='caption'
            ).resize(0.5).set_position(("center", clip.h + subtitle_y_position))

            # íŒì—… ì• ë‹ˆë©”ì´ì…˜ ì ìš© (ì„ ëª…ë„ ìœ ì§€)
            pop = txt.resize(lambda t: 0.3 + 0.7 * (t / 0.2) if t < 0.2 else 1)
            pop = pop.set_start(local_start).set_duration(duration)
            word_clips.append(pop)

        final = CompositeVideoClip([clip] + word_clips).set_duration(clip.duration)
        video_clips.append(final)

    return video_clips


