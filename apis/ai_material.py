# ì‚¬ìš©ìì˜ ì…ë ¥ì„ í†µí•´ ìë§‰ê³¼ ì´ë¯¸ì§€ ìƒì„± ë° ë°˜í™˜
from fastapi import APIRouter
from pydantic import BaseModel
import openai
import os
import requests

router = APIRouter()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
STABLE_DIFFUSION_API_KEY = os.getenv("STABLE_DIFFUSION_API_KEY")

client = openai.OpenAI(api_key=OPENAI_API_KEY)

# âœ… ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜
class MaterialRequest(BaseModel):
    title: str
    duration: int

# OpenAI API í˜¸ì¶œ í•¨ìˆ˜
def generate_script(title: str, duration: int):
    segments = duration // 5  # 5ì´ˆì— 1ê°œì”© ìë§‰ ìƒì„±
    prompt = f"""
    {title} ì£¼ì œì— ë§ëŠ” ìˆí¼ ëŒ€ë³¸ì„ ìƒì„±í•´ì¤˜. ì´ {segments}ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•˜ê³ , ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 12ê°œì˜ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•´. ë²ˆí˜¸ ì—†ì´ ë¬¸ì¥ë§Œ ì¶œë ¥í•´ì¤˜.
    """.strip()
    #12ê°œ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ë¬¸ì¥ì„ 1.15 ì†ë„ë¡œ í–ˆì„ ë•Œ 5ì´ˆì— ê°€ê¹ê²Œ ìƒì„±
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "ë„ˆëŠ” ìˆí¼ ì˜ìƒ ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                  {"role": "user", "content": prompt}],
    )
    
    # âœ… OpenAI ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    raw_script = response.choices[0].message.content.split("\n")
    return raw_script[:segments]

# âœ… ì „ì²´ subtitles ë¦¬ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­
def translate_to_english(text_list: list):
    text = "\n".join(text_list)  # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
    prompt = f"Translate the following Korean text into natural English:\n\n{text}"
    
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "You are a professional Korean-to-English translator."},
                  {"role": "user", "content": prompt}],
    )
    
    translated_text = response.choices[0].message.content.strip()
    translated_subtitles = translated_text.split("\n")

    return translated_subtitles

# âœ… ëŒ€ë³¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_image_prompt(subtitles):
    text = "\n".join(subtitles)
    prompt = f"""
        Generate a suitable image description for each of the following subtitles. 
        The description should be highly detailed and optimized for AI-based image generation. 
        Do not include the original subtitles in the responseâ€”only provide the descriptions.

        Subtitles:
        {text}

        Output:
        - Each description must be on a separate line.
        - Ensure the descriptions are vivid, creative, and directly relevant to the subtitle.
        - Do not include any extra text or formatting.
        """.strip()
    
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "You are an AI that generates highly detailed image descriptions for Stable Diffusion."},
                  {"role": "user", "content": prompt}],
    )

    # âœ… ë¹ˆ ë¬¸ìì—´ ì œê±°í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì •ë¦¬
    generated_prompts = [p.strip() for p in response.choices[0].message.content.strip().split("\n") if p.strip()]

    return generated_prompts

# Stable Diffusion API í˜¸ì¶œ í•¨ìˆ˜
def generate_images(subtitles):
    image_urls = []
    max_images = 2

    if not os.path.exists("images"):
        os.makedirs("images")

    # âœ… ì „ì²´ ë¬¸ì¥ì„ ë²ˆì—­ (ë¬´ì¡°ê±´ ì‹¤í–‰)
    translated_subtitles = translate_to_english(subtitles)

    # âœ… ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
    image_prompts = generate_image_prompt(translated_subtitles)

    for i, prompt in enumerate(image_prompts[:max_images]):  # âœ… for ë£¨í”„ ì¶”ê°€

        # âœ… API ìš”ì²­
        response = requests.post(
            "https://api.stability.ai/v2beta/stable-image/generate/sd3",
            headers={
                "Authorization": f"Bearer {STABLE_DIFFUSION_API_KEY}",
                "Accept": "image/*",  # ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ë°›ê¸°
            },
            files={"none": ""},  # âœ… Multipart í˜•ì‹ ì¶©ì¡±ì„ ìœ„í•´ í•„ìš”
            data={
                "model": "sd3.5-large-turbo",
                "prompt": prompt,  # âœ… ë²ˆì—­ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                "aspect_ratio": "9:16",
                "output_format": "jpeg",
            },
        )

        # âœ… ì‘ë‹µ í™•ì¸ í›„ ì €ì¥
        if response.status_code == 200:
            image_filename = f"images/generated_image_{i}.jpeg"
            with open(image_filename, "wb") as img_file:
                img_file.write(response.content)  # âœ… Base64 ë””ì½”ë”© ë¶ˆí•„ìš”
            image_urls.append(f"http://127.0.0.1:8000/images/generated_image_{i}.jpeg")
            print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {image_filename}")
        else:
            print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {response.status_code} - {response.text}")
            image_urls.append(None)

    return image_urls


# âœ… FastAPI ì—”ë“œí¬ì¸íŠ¸ (Request Body ì‚¬ìš©)
@router.post("/")
async def generate_material(request: MaterialRequest):
    print("\nğŸš€ OpenAI ëŒ€ë³¸ ìƒì„± ì‹œì‘!")
    subtitles = generate_script(request.title, request.duration)

    print("\nâœ… ìƒì„±ëœ ëŒ€ë³¸:", subtitles)  # ğŸš€ OpenAIì—ì„œ ë°›ì€ ëŒ€ë³¸ í™•ì¸

    print("\nğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘!")
    image_urls = generate_images(subtitles)

    print("\nâœ… ìƒì„±ëœ ì´ë¯¸ì§€ URL:", image_urls)  # ğŸš€ ì´ë¯¸ì§€ URL í™•ì¸

    # âœ… ìµœì¢… ë°˜í™˜ë˜ëŠ” JSON ë°ì´í„° í™•ì¸
    response_data = {"subtitles": subtitles, "image_urls": image_urls}
    print("\nâœ… ìµœì¢… ë°˜í™˜ ê°’:", response_data)

    return response_data

# ìë§‰ ìƒì„± ì•½ 10ì´ˆ, ì˜ë¬¸ ë³€í™˜ ì•½ 5ì´ˆ, í”„ë¡¬í”„íŠ¸ ìƒì„± ì•½ 10ì´ˆ, ì´ë¯¸ì§€ í•˜ë‚˜ ìƒì„± ì•½ 3.5ì´ˆ