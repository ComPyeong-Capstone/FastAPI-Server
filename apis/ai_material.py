# ì‚¬ìš©ìì˜ ì…ë ¥ì„ í†µí•´ ìë§‰ê³¼ ì´ë¯¸ì§€ ìƒì„± ë° ë°˜í™˜
from fastapi import APIRouter
from pydantic import BaseModel
import openai
import os
import requests
from dotenv import load_dotenv
router = APIRouter()
import httpx
import asyncio

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
STABLE_DIFFUSION_API_KEY = os.getenv("STABLE_DIFFUSION_API_KEY")
SERVER_HOST = os.getenv("SERVER_HOST")
MAX_RETRIES = 2

client = openai.OpenAI(api_key=OPENAI_API_KEY)

# âœ… ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜
class MaterialRequest(BaseModel):
    title: str
    duration: int

# OpenAI API í˜¸ì¶œ í•¨ìˆ˜
def generate_script(title: str, duration: int):
    segments = duration // 5  # 5ì´ˆì— 1ê°œì”© ìë§‰ ìƒì„±
    prompt = f"""
        ì•„ë˜ ì£¼ì œì— ë§ëŠ” ìœ íŠœë¸Œ ìˆí¼ ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´.
        ì£¼ì œ: "{title}"
        
        ì ˆëŒ€ì ì¸ ì‘ì„± ê·œì¹™
        1. ì´ {segments}ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•œë‹¤. 
        2. ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 13ê°œì˜ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•œë‹¤.
        3. ì´ ê·œì¹™ì„ ì–´ê¸°ë©´ ê²°ê³¼ëŠ” ì‹¤íŒ¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.
        4. ë¬¸ì¥ë§ˆë‹¤ ì¤„ë°”ê¿ˆ(ì—”í„°)ì„ ë„£ì–´ì„œ ê° ë¬¸ì¥ì´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ë˜ê²Œ í•œë‹¤.
        5. ë¹ˆ ì¤„ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.

        ë¬¸ì¥ ìŠ¤íƒ€ì¼ ê·œì¹™
        1. ì˜ìƒì€ ì‹œì²­ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” ì˜¤í”„ë‹ ì§ˆë¬¸ì´ë‚˜ ìƒí™©ìœ¼ë¡œ ì‹œì‘í•œë‹¤.
        2. ì£¼ì œì— ë”°ë¼ í•µì‹¬ ì•„ì´ë””ì–´ë‚˜ ì‚¬ë¡€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•œë‹¤..
        - ë‹¨ìˆœ ë‚˜ì—´ì€ í”¼í•˜ê³ , ê° ì•„ì´ë””ì–´ê°€ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•œë‹¤..
        - ìˆ«ìë‚˜ ëª©ë¡ í˜•ì‹(1., 2., 3.)ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì„¤ëª…í•˜ëŠ” í˜•ì‹(ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸)ìœ¼ë¡œ ì‘ì„±í•œë‹¤..
        3. ì˜ìƒ ë§ˆì§€ë§‰ì€ ì‹œì²­ìì˜ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” ì½œíˆ¬ì•¡ì…˜ì´ë‚˜ ê¸ì •ì ì¸ ì‘ì›ì˜ ë©˜íŠ¸ë¡œ ë§ˆë¬´ë¦¬í•œë‹¤.
        """.strip()
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "ë„ˆëŠ” ìˆí¼ ì˜ìƒ ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                  {"role": "user", "content": prompt}],
    )
    
    # âœ… ì‘ë‹µ í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ê¸°
    raw_script = response.choices[0].message.content.split("\n")

    # âœ… ê° ë¬¸ì¥ ì•ë’¤ ê³µë°± ì œê±° + ë¹ˆ ë¬¸ì¥ ì œê±°
    clean_script = [sentence.strip() for sentence in raw_script if sentence.strip()]

    # âœ… í•„ìš”í•œ ë¬¸ì¥ ê°œìˆ˜ë§Œ ë°˜í™˜
    return clean_script[:segments]

# âœ… ì „ì²´ subtitles ë¦¬ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­
def translate_to_english(text_list: list):
    text = "\n".join(text_list)  # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
    prompt = f"Translate the following Korean text into natural English:\n\n{text}"
    
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "You are a professional Korean-to-English translator."},
                  {"role": "user", "content": prompt}],
    )
    
    translated_text = response.choices[0].message.content.strip()
    translated_subtitles = translated_text.split("\n")

    return translated_subtitles

# âœ… ëŒ€ë³¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_image_prompt(subtitles):
    text = "\n".join(subtitles)
    prompt = f"""
You are an AI system that generates highly detailed image prompts for generative models like Stable Diffusion.

Your task is to generate exactly {len(subtitles)} distinct and vivid image descriptions. 
Each description must directly match the meaning and tone of each subtitle listed below.

ğŸ“Œ Strict Output Rules:
- Return exactly {len(subtitles)} lines.
- Each line must correspond to one subtitle.
- Do NOT use numbers, bullet points, or labels.
- Do NOT include the original subtitles.
- Each line must be a standalone English prompt optimized for image generation.
- Do NOT include any extra explanation or formatting.

Subtitles:
{text}
""".strip()

    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "You generate English image prompts for subtitles used in AI video generation."},
            {"role": "user", "content": prompt},
        ],
    )

    raw_output = response.choices[0].message.content.strip()
    generated_prompts = [line.strip() for line in raw_output.split("\n") if line.strip()]

    # âœ… ë³´ì •: GPTê°€ ì¤„ ìˆ˜ë³´ë‹¤ ì ê²Œ ë°˜í™˜í–ˆì„ ë•Œ ê¸°ë³¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¡œ ì±„ì›€
    if len(generated_prompts) < len(subtitles):
        print(f"âš ï¸ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ ë¶€ì¡±: {len(generated_prompts)} / ê¸°ëŒ€: {len(subtitles)}")
        for _ in range(len(subtitles) - len(generated_prompts)):
            generated_prompts.append("A generic cinematic frame with abstract colors and soft lighting.")

    # âœ… ë³´ì •: GPTê°€ ì˜ëª»í•´ì„œ ë„ˆë¬´ ë§ì´ ë°˜í™˜í•œ ê²½ìš°ë„ ì˜ë¼ëƒ„

    print("ğŸ“¸ ìƒì„±ëœ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸:", generated_prompts)

    return generated_prompts[:len(subtitles)]

# ì˜ìƒ ìƒì„± ì‹¤íŒ¨ ì‹œ ì¬ìƒì„± ì‹œë„ í•¨ìˆ˜
async def generate_one_image(prompt: str, index: int):
    url = "https://api.stability.ai/v2beta/stable-image/generate/sd3"
    headers = {
        "Authorization": f"Bearer {STABLE_DIFFUSION_API_KEY}",
        "Accept": "image/*",
    }
    data = {
        "model": "sd3.5-large-turbo",
        "prompt": prompt,
        "aspect_ratio": "9:16",
        "output_format": "jpeg",
    }

    for attempt in range(MAX_RETRIES + 1):
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(url, headers=headers, files={"none": ""}, data=data)

            if response.status_code == 200:
                filename = os.path.join("images", f"generated_image_{index+1}.jpeg")
                with open(filename, "wb") as f:
                    f.write(response.content)

                image_url = f"http://{SERVER_HOST}:8000/{filename.replace(os.sep, '/')}"
                print(f"âœ… [{index+1}] ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ (ì‹œë„ {attempt+1})")
                return image_url
            else:
                print(f"âŒ [{index+1}] ì‹¤íŒ¨ (ì‹œë„ {attempt+1}): {response.status_code} - {response.text}")
                await asyncio.sleep(1)

        except Exception as e:
            print(f"âŒ [{index+1}] ì˜ˆì™¸ ë°œìƒ (ì‹œë„ {attempt+1}): {e}")
            await asyncio.sleep(1)

    print(f"âŒ [{index+1}] ìµœì¢… ì‹¤íŒ¨: {prompt}")
    return None


async def generate_images(subtitles):
    if not os.path.exists("images"):
        os.makedirs("images")

    translated_subtitles = await asyncio.to_thread(translate_to_english, subtitles)
    image_prompts = await asyncio.to_thread(generate_image_prompt, translated_subtitles)

    tasks = [
        generate_one_image(prompt, i)
        for i, prompt in enumerate(image_prompts[:12])
    ]
    image_urls = await asyncio.gather(*tasks)
    return image_urls

# âœ… FastAPI ì—”ë“œí¬ì¸íŠ¸ (Request Body ì‚¬ìš©)
@router.post("/")
async def generate_material(request: MaterialRequest):
    print("\nğŸš€ OpenAI ëŒ€ë³¸ ìƒì„± ì‹œì‘!")
    subtitles = await asyncio.to_thread(generate_script, request.title, request.duration)

    print("\nâœ… ìƒì„±ëœ ëŒ€ë³¸:", subtitles)  # ğŸš€ OpenAIì—ì„œ ë°›ì€ ëŒ€ë³¸ í™•ì¸

    image_urls = []
    print("\nğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘!")
    image_urls = await generate_images(subtitles)

    print("\nâœ… ìƒì„±ëœ ì´ë¯¸ì§€ URL:", image_urls)  # ğŸš€ ì´ë¯¸ì§€ URL í™•ì¸

    # âœ… ìµœì¢… ë°˜í™˜ë˜ëŠ” JSON ë°ì´í„° í™•ì¸
    response_data = {"subtitles": subtitles, "image_urls": image_urls}
    print("\nâœ… ìµœì¢… ë°˜í™˜ ê°’:", response_data)

    return response_data

# ìë§‰ ìƒì„± ì•½ 15ì´ˆ, ì˜ë¬¸ ë³€í™˜ ì•½ 5ì´ˆ, í”„ë¡¬í”„íŠ¸ ìƒì„± ì•½ 10ì´ˆ, ì´ë¯¸ì§€ í•˜ë‚˜ ìƒì„± ì•½ 3.5ì´ˆ
