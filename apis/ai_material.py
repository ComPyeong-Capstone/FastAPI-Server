# ì‚¬ìš©ìì˜ ì…ë ¥ì„ í†µí•´ ìë§‰ê³¼ ì´ë¯¸ì§€ ìƒì„± ë° ë°˜í™˜
from fastapi import APIRouter
from pydantic import BaseModel
import openai
import os
import requests
from typing import List
from dotenv import load_dotenv
router = APIRouter()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
STABLE_DIFFUSION_API_KEY = os.getenv("STABLE_DIFFUSION_API_KEY")
SERVER_HOST = os.getenv("SERVER_HOST")

client = openai.OpenAI(api_key=OPENAI_API_KEY)

# âœ… ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜
class MaterialRequest(BaseModel):
    title: str
    duration: int

# OpenAI API í˜¸ì¶œ í•¨ìˆ˜
def generate_script(title: str, duration: int):
    segments = duration // 5  # 5ì´ˆì— 1ê°œì”© ìë§‰ ìƒì„±
    prompt = f"""
        ì•„ë˜ ì£¼ì œì— ë§ëŠ” ìœ íŠœë¸Œ ìˆí¼ ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´.
        ì£¼ì œ: "{title}"
        
        ì ˆëŒ€ì ì¸ ì‘ì„± ê·œì¹™
        1. ì´ {segments}ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•œë‹¤. 
        2. ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ 13ê°œì˜ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•œë‹¤.
        3. ì´ ê·œì¹™ì„ ì–´ê¸°ë©´ ê²°ê³¼ëŠ” ì‹¤íŒ¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.
        4. ë¬¸ì¥ë§ˆë‹¤ ì¤„ë°”ê¿ˆ(ì—”í„°)ì„ ë„£ì–´ì„œ ê° ë¬¸ì¥ì´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ë˜ê²Œ í•œë‹¤.
        5. ë¹ˆ ì¤„ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.

        ë¬¸ì¥ ìŠ¤íƒ€ì¼ ê·œì¹™
        1. ì˜ìƒì€ ì‹œì²­ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” ì˜¤í”„ë‹ ì§ˆë¬¸ì´ë‚˜ ìƒí™©ìœ¼ë¡œ ì‹œì‘í•œë‹¤.
        2. ì£¼ì œì— ë”°ë¼ í•µì‹¬ ì•„ì´ë””ì–´ë‚˜ ì‚¬ë¡€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•œë‹¤..
        - ë‹¨ìˆœ ë‚˜ì—´ì€ í”¼í•˜ê³ , ê° ì•„ì´ë””ì–´ê°€ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•œë‹¤..
        - ìˆ«ìë‚˜ ëª©ë¡ í˜•ì‹(1., 2., 3.)ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì„¤ëª…í•˜ëŠ” í˜•ì‹(ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸)ìœ¼ë¡œ ì‘ì„±í•œë‹¤..
        3. ì˜ìƒ ë§ˆì§€ë§‰ì€ ì‹œì²­ìì˜ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” ì½œíˆ¬ì•¡ì…˜ì´ë‚˜ ê¸ì •ì ì¸ ì‘ì›ì˜ ë©˜íŠ¸ë¡œ ë§ˆë¬´ë¦¬í•œë‹¤.
        """.strip()
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "ë„ˆëŠ” ìˆí¼ ì˜ìƒ ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                  {"role": "user", "content": prompt}],
    )
    
    # âœ… ì‘ë‹µ í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ê¸°
    raw_script = response.choices[0].message.content.split("\n")

    # âœ… ê° ë¬¸ì¥ ì•ë’¤ ê³µë°± ì œê±° + ë¹ˆ ë¬¸ì¥ ì œê±°
    clean_script = [sentence.strip() for sentence in raw_script if sentence.strip()]

    # âœ… í•„ìš”í•œ ë¬¸ì¥ ê°œìˆ˜ë§Œ ë°˜í™˜
    return clean_script[:segments]

# âœ… ì „ì²´ subtitles ë¦¬ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­
def translate_to_english(text_list: list):
    text = "\n".join(text_list)  # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
    prompt = f"Translate the following Korean text into natural English:\n\n{text}"
    
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "You are a professional Korean-to-English translator."},
                  {"role": "user", "content": prompt}],
    )
    
    translated_text = response.choices[0].message.content.strip()
    translated_subtitles = translated_text.split("\n")

    return translated_subtitles

# âœ… ëŒ€ë³¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_image_prompt(subtitles):
    text = "\n".join(subtitles)
    prompt = f"""
        Generate a suitable image description for each of the following subtitles. 
        The description should be highly detailed and optimized for AI-based image generation. 
        Do not include the original subtitles in the responseâ€”only provide the descriptions.

        Subtitles:
        {text}

        Output:
        - You must generate exactly {len(subtitles)} image descriptions.
        - Each description must be on a separate line.
        - Ensure the descriptions are vivid, creative, and directly relevant to the subtitle.
        - Do not include any extra text or formatting.
        """.strip()
    
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "system", "content": "You are an AI that generates highly detailed image descriptions for Stable Diffusion."},
                  {"role": "user", "content": prompt}],
    )

    # âœ… ë¹ˆ ë¬¸ìì—´ ì œê±°í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì •ë¦¬
    generated_prompts = [p.strip() for p in response.choices[0].message.content.strip().split("\n") if p.strip()]

    return generated_prompts

# Stable Diffusion API í˜¸ì¶œ í•¨ìˆ˜
def generate_images(subtitles):
    image_urls = []
    max_images = 12

    if not os.path.exists("images"):
        os.makedirs("images")

    # âœ… í˜„ì¬ ì´ë¯¸ì§€ ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê³ ìœ  ë²ˆí˜¸ ì‹œì‘ì  ê³„ì‚°
    # existing_images = [f for f in os.listdir("images") if f.endswith(".jpeg")]
    # start_index = len(existing_images)

    translated_subtitles = translate_to_english(subtitles)
    image_prompts = generate_image_prompt(translated_subtitles)

    for i, prompt in enumerate(image_prompts[:max_images]):
        response = requests.post(
            "https://api.stability.ai/v2beta/stable-image/generate/sd3",
            headers={
                "Authorization": f"Bearer {STABLE_DIFFUSION_API_KEY}",
                "Accept": "image/*",
            },
            files={"none": ""},
            data={
                "model": "sd3.5-large-turbo",
                "prompt": prompt,
                "aspect_ratio": "9:16",
                "output_format": "jpeg",
            },
        )

        if response.status_code == 200:
            image_filename = os.path.join("images", f"generated_image_{i+1}.jpeg")
            # unique_index = start_index + i
            # image_filename = os.path.join("images", f"generated_image_{unique_index}.jpeg")

            with open(image_filename, "wb") as img_file:
                img_file.write(response.content)

            image_url = f"http://{SERVER_HOST}:8000/{image_filename.replace(os.sep, '/')}"
            image_urls.append(image_url)

            print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {image_filename}")
        else:
            print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {response.status_code} - {response.text}")
            image_urls.append(None)

    return image_urls


# âœ… FastAPI ì—”ë“œí¬ì¸íŠ¸ (Request Body ì‚¬ìš©)
@router.post("/")
async def generate_material(request: MaterialRequest):
    print("\nğŸš€ OpenAI ëŒ€ë³¸ ìƒì„± ì‹œì‘!")
    subtitles = generate_script(request.title, request.duration)

    print("\nâœ… ìƒì„±ëœ ëŒ€ë³¸:", subtitles)  # ğŸš€ OpenAIì—ì„œ ë°›ì€ ëŒ€ë³¸ í™•ì¸

    image_urls = []
    print("\nğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘!")
    image_urls = generate_images(subtitles)

    print("\nâœ… ìƒì„±ëœ ì´ë¯¸ì§€ URL:", image_urls)  # ğŸš€ ì´ë¯¸ì§€ URL í™•ì¸

    # âœ… ìµœì¢… ë°˜í™˜ë˜ëŠ” JSON ë°ì´í„° í™•ì¸
    response_data = {"subtitles": subtitles, "image_urls": image_urls}
    print("\nâœ… ìµœì¢… ë°˜í™˜ ê°’:", response_data)

    return response_data

# ìë§‰ ìƒì„± ì•½ 15ì´ˆ, ì˜ë¬¸ ë³€í™˜ ì•½ 5ì´ˆ, í”„ë¡¬í”„íŠ¸ ìƒì„± ì•½ 10ì´ˆ, ì´ë¯¸ì§€ í•˜ë‚˜ ìƒì„± ì•½ 3.5ì´ˆ
