import requests
import json
import base64
import os
import whisper
from pydub import AudioSegment

# ğŸ”¹ Google Cloud API í‚¤
GOOGLE_TTS_API_KEY = ""

# ğŸ”¹ API ìš”ì²­ URL
url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={GOOGLE_TTS_API_KEY}"

# ğŸ”¹ TTS ìŒì„±ì´ ì €ì¥ë  í´ë” ê²½ë¡œ
output_folder = os.path.expanduser("~/Desktop/FASTAPI-SERVER/TTSfile")

# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
os.makedirs(output_folder, exist_ok=True)

def get_next_filename():
    """
    í˜„ì¬ í´ë”ì— ì €ì¥ëœ TTS íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•˜ê³ ,
    'tts_output_X.mp3' í˜•ì‹ì˜ íŒŒì¼ëª…ì„ ìë™ìœ¼ë¡œ ì¦ê°€ì‹œì¼œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    existing_files = [f for f in os.listdir(output_folder) if f.startswith("tts_output") and f.endswith(".mp3")]
    numbers = [
        int(f.replace("tts_output_", "").replace(".mp3", ""))
        for f in existing_files if f.replace("tts_output_", "").replace(".mp3", "").isdigit()
    ]
    next_number = max(numbers) + 1 if numbers else 1
    return f"tts_output_{next_number}.mp3"

def generate_tts(text):
    """
    Google Cloud Text-to-Speech APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„± ë°ì´í„°(MP3)ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.
    ë³€í™˜ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°˜í™˜í•œë‹¤.
    """
    voice_name = "ko-KR-Wavenet-C"
    data = {
        "input": {"text": text},
        "voice": {
            "languageCode": "ko-KR",
            "name": voice_name,
            "ssmlGender": "MALE"
        },
        "audioConfig": {
            "audioEncoding": "MP3",
            "speakingRate": 1.25
        }
    }
    response = requests.post(url, headers={"Content-Type": "application/json"}, data=json.dumps(data))
    
    if response.status_code == 200:
        response_data = response.json()
        audio_content = response_data["audioContent"]
        return base64.b64decode(audio_content)
    else:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {response.text}")
        return None



def text_to_speech(text_list):
    """
    ì…ë ¥ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ TTS ë³€í™˜í•œ í›„,
    ê° ë¬¸ì¥ì˜ ì‹œì‘ ì‹œê°„ì„ 5ì´ˆ ê°„ê²©ìœ¼ë¡œ ë§ì¶° í•˜ë‚˜ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜.
    """
    if not isinstance(text_list, list):
        raise ValueError("ì…ë ¥ì€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    combined_audio = AudioSegment.silent(duration=0)  # ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ (ì´ˆê¸° ë¬´ìŒ ìƒíƒœ)
    start_time = 0  # ë¬¸ì¥ë³„ ì‹œì‘ ì‹œê°„ (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
    interval = 5000  # ê° ë¬¸ì¥ì´ ì‹œì‘í•˜ëŠ” ê°„ê²© (5ì´ˆ = 5000ms)
    
    for idx, text in enumerate(text_list):
        print(f"ğŸ”¹ {idx * 5}ì´ˆì— ì‹œì‘í•  ë¬¸ì¥: {text}")
        
        audio_data = generate_tts(text)  # TTS ë³€í™˜ ì‹¤í–‰
        if audio_data:
            temp_audio_path = os.path.join(output_folder, f"temp_tts_{idx}.mp3")
            with open(temp_audio_path, "wb") as f:
                f.write(audio_data)
            
            tts_audio = AudioSegment.from_mp3(temp_audio_path)  # ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            
            # í˜„ì¬ ë¬¸ì¥ì´ ì •í™•íˆ start_timeì— ì‹œì‘ë˜ë„ë¡ ê³µë°± ì¶”ê°€
            silent_gap = AudioSegment.silent(duration=max(0, start_time - len(combined_audio)))
            combined_audio += silent_gap + tts_audio
            
            start_time += interval  # ë‹¤ìŒ ë¬¸ì¥ ì‹œì‘ ì‹œì  ì—…ë°ì´íŠ¸ (5ì´ˆ ì¶”ê°€)
            os.remove(temp_audio_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    
    output_file = os.path.join(output_folder, get_next_filename())
    combined_audio.export(output_file, format="mp3")  # ìµœì¢… ìŒì„± íŒŒì¼ ì €ì¥
    print(f"âœ… TTS ìŒì„± íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
    
    analyze_audio_with_whisper(output_file)  # Whisper ë¶„ì„ ì‹¤í–‰



def analyze_audio_with_whisper(audio_file):
    """
    Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ìŒì„± íŒŒì¼ì„ ë¶„ì„í•˜ê³ ,
    ìŒì„± ë‚´ ê° ë¬¸ì¥ì˜ ì‹œì‘ ë° ë ì‹œê°„ì„ í„°ë¯¸ë„ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜.
    """
    model = whisper.load_model("medium")
    result = model.transcribe(audio_file, word_timestamps=True)
    
    print("\nğŸ” [Whisper ë¶„ì„ ê²°ê³¼] ğŸ”")
    print(f"ğŸµ íŒŒì¼ëª…: {audio_file}\n")
    
    for segment in result["segments"]:
        start_time = round(segment["start"], 2)
        end_time = round(segment["end"], 2)
        text = segment["text"]
        print(f"â± {start_time}ì´ˆ ~ {end_time}ì´ˆ: {text}")
    
    print("\n" + "-" * 50 + "\n")

# ğŸ”¹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
subtitles = [
    "ì½”ë“œë¥¼ ì‘ì„±í•  ë•Œ ì£¼ì„ì„ ì¶©ë¶„íˆ ë‹¬ì§€ ì•ŠëŠ” ì‹¤ìˆ˜ë¥¼ ì¢…ì¢… í•©ë‹ˆë‹¤.",
    "ë³€ìˆ˜ëª…ì„ ëª…í™•í•˜ì§€ ì•Šê²Œ ì§€ì–´ì„œ ë‚˜ì¤‘ì— í˜¼ë€ì„ ê²ªê²Œ ë˜ì£ .",
    "ë°±ì—… ì—†ì´ ì¤‘ìš”í•œ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.",
    "ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì œëŒ€ë¡œ ì½ì§€ ì•Šê³  ë„˜ì–´ê°€ëŠ” ê²½ìš°ë„ í”í•´ìš”."
]

subtitles2 = [
    "ë™í•´ë¬¼ê³¼ ë°±ë‘ì‚°ì´ ë§ˆë¥´ê³  ë‹³ë„ë¡.",
    "í•˜ëŠë‹˜ì´ ë³´ìš°í•˜ì‚¬ ìš°ë¦¬ë‚˜ë¼ ë§Œì„¸.",
    "ë¬´ê¶í™” ì‚¼ì²œë¦¬ í™”ë ¤ê°•ì‚°",
    "ëŒ€í•œì‚¬ëŒ ëŒ€í•œìœ¼ë¡œ ê¸¸ì´ ë³´ì „í•˜ì„¸"
]

text_to_speech(subtitles)
text_to_speech(subtitles2)
